AWSTemplateFormatVersion: '2010-09-09'


Description: Let's build a data pipeline!


Parameters:

  VPCCIDR:
    Description: Please enter the IP range (CIDR notation) for this VPC
    Type: String

  PrivateSubnetCIDR:
    Description: Please enter the IP range (CIDR notation) for the private subnet in the first Availability Zone
    Type: String

  IPADDRESS:
    Description: IP address from which the AWS resources will be created
    Type: String

  S3BucketName:
    Description: S3 bucket name.
    Type: String

  S3ObjectKey:
    Description: S3 key at which to find the input data in S3BucketName.
    Type: String

  LambdaFunctionName:
    Description: Lambda function that the data at S3ObjectKey to writes to DynamoDBTableName.
    Type: String

  DynamoDBTableName:
    Description: DynamoDB table containing the data.
    Type: String

Resources:

  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VPCCIDR
      EnableDnsSupport: true
      EnableDnsHostnames: true

  PrivateSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 0, !GetAZs  '' ]
      CidrBlock: !Ref PrivateSubnetCIDR
      MapPublicIpOnLaunch: false

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC

  PrivateSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet

  VPCEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        - Effect: Allow
          Principal:
            Service:
              - lambda.amazonaws.com
          Action:
            - dynamodb:PutItem
            - dynamodb:GetItem
            - dynamodb:Scan
            - dynamodb:Query
            - dynamodb:UpdateItem
          Resource:
            - !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${DynamoDBTableName}'
      RouteTableIds:
        - !Ref PrivateRouteTable
      ServiceName: !Sub 'com.amazonaws.${AWS::Region}.dynamodb'
      VpcEndpointType: Gateway
      VpcId: !Ref VPC

  S3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3BucketName
      PolicyDocument:
          Version: 2012-10-17
          Statement:
          - Effect: Allow
            Principal: '*'
            Action:
              - s3:*
            Resource:
              - !Sub 'arn:aws:s3:::${S3BucketName}/*'
            Condition:
              IpAddress:
                aws:SourceIp:
                  - !Ref IPADDRESS

  S3Bucket:
    DependsOn:
      - LambdaFunction
      - S3BucketPermission
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref S3BucketName
      AccessControl: BucketOwnerFullControl
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:*
            Function: !GetAtt
              - LambdaFunction
              - Arn

  S3BucketPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref LambdaFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref AWS::AccountId

  LambdaFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
                - s3.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AWSLambdaInvocation-DynamoDB
        - arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess
      Policies:
        - PolicyName: policyname
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Resource: '*'
                Action:
                  - dynamodb:PutItem
                  - dynamodb:BatchWriteItem

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Ref LambdaFunctionName
      Handler: index.lambda_handler
      Role: !GetAtt
        - LambdaFunctionRole
        - Arn
      Code:
        ZipFile: !Join
          - |+

          - - import json
            - import boto3
            - import os
            - import csv
            - import codecs
            - ''
            - ''
            - 'S3_BUCKET = os.environ[''S3_BUCKET'']'
            - 'S3_OBJECT_KEY = os.environ[''S3_OBJECT_KEY'']'
            - 'DYNAMODB_TABLE_NAME = os.environ[''DYNAMODB_TABLE_NAME'']'
            - ''
            - ''
            - s3 = boto3.resource('s3')
            - dynamodb = boto3.resource('dynamodb')
            - ''
            - ''
            - 'def lambda_handler(event, context):'
            - ''
            - ''
            - '   try:'
            - '       print("Getting data from s3://{0}/{1}.".format(S3_BUCKET, S3_OBJECT_KEY))'
            - '       obj = s3.Object(S3_BUCKET, S3_OBJECT_KEY).get()[''Body'']'
            - '   except:'
            - '       print("S3 Object could not be opened. Check environment variables.")'
            - ''
            - '   batch_size = 100'
            - '   batch = []'
            - ''
            - '   for row in csv.DictReader(codecs.getreader(''utf-8'')(obj)):'
            - '      if len(batch) >= batch_size:'
            - '         write_to_dynamo(batch)'
            - '         batch.clear()'
            - ''
            - '      batch.append(row)'
            - ''
            - '   if batch:'
            - '      write_to_dynamo(batch)'
            - ''
            - '   return {'
            - '      ''statusCode'': 200,'
            - '      ''body'': json.dumps(''Uploaded to DynamoDB Table.'')'
            - '   }'
            - ''
            - ''
            - 'def write_to_dynamo(rows):'
            - ''
            - '   try:'
            - '      print("Loading {0}.".format(DYNAMODB_TABLE_NAME))'
            - '      table = dynamodb.Table(DYNAMODB_TABLE_NAME)'
            - '   except:'
            - '      print("Error loading DynamoDB table. Confirm that the table was created correctly, and check environment variables.")'
            - ''
            - '   try:'
            - '      print("Writing data to {0}.".format(DYNAMODB_TABLE_NAME))'
            - '      with table.batch_writer() as batch:'
            - '         for i in range(len(rows)):'
            - '            batch.put_item('
            - '               Item=rows[i]'
            - '            )'
            - '   except:'
            - '      print("Error executing batch_writer.")'
      Runtime: python3.7
      Timeout: 900
      MemorySize: 3008
      Environment:
        Variables:
          S3_BUCKET: !Ref S3BucketName
          S3_OBJECT_KEY: !Ref S3ObjectKey
          DYNAMODB_TABLE_NAME: !Ref DynamoDBTableName

  DynamoDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Ref DynamoDBTableName
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: Employee_SSN
          AttributeType: S
      KeySchema:
        - AttributeName: Employee_SSN
          KeyType: HASH
